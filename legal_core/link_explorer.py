import os
import sys
import django
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time

# ØªÙ‡ÙŠØ¦Ø© Ø¨ÙŠØ¦Ø© Django
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'hujja_platform.settings')
django.setup()

from legal_core.models import LegalReference
from django.core.files.base import ContentFile


def explore_and_import_pdfs(target_url, country, tags):
    print(f"ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‚ÙˆØ§Ù†ÙŠÙ† ÙÙŠ: {target_url}...")
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}

    try:
        response = requests.get(target_url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')

        # 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙÙŠ Ø§Ù„ØµÙØ­Ø©
        all_links = soup.find_all('a', href=True)
        pdf_links = set()  # Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ set Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±

        print(f"ğŸ” ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(all_links)} Ø±Ø§Ø¨Ø·ØŒ Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª...")

        for link in all_links:
            href = link['href']
            full_url = urljoin(target_url, href)

            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙŠØ¤Ø¯ÙŠ Ù„Ù…Ù„Ù PDF Ù…Ø¨Ø§Ø´Ø±Ø©
            if full_url.lower().endswith('.pdf'):
                pdf_links.add((full_url, link.text.strip()))

            # Ù…ÙŠØ²Ø© Ø¥Ø¶Ø§ÙÙŠØ©: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© "download" Ø£Ùˆ "view"
            # Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø²ÙŠØ§Ø±ØªÙ‡ Ø³Ø±ÙŠØ¹Ø§Ù‹ Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† PDF Ø¨Ø¯Ø§Ø®Ù„Ù‡ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¯Ù‚Ø©)

        pdf_count = 0
        for pdf_url, title in pdf_links:
            if not title: title = f"Ù‚Ø§Ù†ÙˆÙ† Ù…ØµØ±ÙŠ {pdf_count + 1}"

            print(f"ğŸ“¥ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ ÙˆØ­ÙØ¸: {title}...")
            try:
                pdf_res = requests.get(pdf_url, headers=headers, timeout=10)
                if pdf_res.status_code == 200:
                    ref = LegalReference(
                        title=title,
                        country=country,
                        ref_type='law',
                        tags=tags,
                        source_url=pdf_url
                    )
                    file_name = f"law_{int(time.time())}_{pdf_count}.pdf"
                    ref.attachment.save(file_name, ContentFile(pdf_res.content), save=True)
                    pdf_count += 1
            except:
                print(f"âš ï¸ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {pdf_url}")

        if pdf_count == 0:
            print(
                "\nğŸ’¡ Ù†ØµÙŠØ­Ø©: Ø¨Ø¹Ø¶ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ ØªØ®ÙÙŠ Ø§Ù„Ù€ PDF Ø®Ù„Ù Ø£Ø²Ø±Ø§Ø± ØªØ­Ù…ÙŠÙ„. Ø¬Ø±Ø¨ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±Ø© Ø£ÙƒØ«Ø± Ø£Ùˆ Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª ÙŠØ¯ÙˆÙŠØ§Ù‹ ÙÙŠ Ù„ÙˆØ­Ø© Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©.")
        else:
            print(f"\nâœ¨ ØªÙ… Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ø¶Ø§ÙØ© {pdf_count} Ù…Ø±Ø¬Ø¹ Ø¬Ø¯ÙŠØ¯ Ù„Ù…ÙƒØªØ¨ØªÙƒ!")

    except Exception as e:
        print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")


if __name__ == "__main__":
    url_to_scan = input("Ø£Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙØ­Ø©: ")
    user_country = input("Ø£Ø¯Ø®Ù„ Ø§Ù„Ø¯ÙˆÙ„Ø©: ")
    explore_and_import_pdfs(url_to_scan, user_country, "Ø§Ø³ØªÙŠØ±Ø§Ø¯_Ø°ÙƒÙŠ")